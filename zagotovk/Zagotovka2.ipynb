{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6db01631",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import glob\n",
    "import re\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import pymorphy2\n",
    "import fitz\n",
    "import string\n",
    "import numpy as np\n",
    "import re\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "from nltk.stem import *\n",
    "from nltk.corpus import stopwords\n",
    "from pymystem3 import Mystem\n",
    "from string import punctuation\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm.auto import tqdm, trange\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import pyLDAvis.sklearn\n",
    "from __future__ import division\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f3b48e",
   "metadata": {},
   "source": [
    "__TitleCompany__ - Название компании\n",
    "\n",
    "__Description__ - Описание компании\n",
    "\n",
    "__Reiting__ - Рейтинг компании\n",
    "\n",
    "__Categories__ - Категории компании\n",
    "\n",
    "\n",
    "__TitleCompany__ - Название компании\n",
    "\n",
    "__Description__ - Описание компании\n",
    "\n",
    "__Reiting__ - Рейтинг компании\n",
    "\n",
    "__Categories__ - Категории компании\n",
    "\n",
    "__TextPostLemat__ - обработанный, лематизированный текст \n",
    "\n",
    "__TextPostToken__ - обработанный, токенизированный и лематизированный текст (лематизирован другим способом нежели TextPostLemat)\n",
    "\n",
    "__bigram__ - биграммы обработанного и лематизированного текста\n",
    "\n",
    "__trigram__ - триграммы обработанного и лематизированного текста\n",
    "\n",
    "__keyword__ - ключевые слова обработанного и лематизированного текста\n",
    "\n",
    "__clustersAgglomerative__ - кластеры, образованные моделью Agglomerative\n",
    "\n",
    "__clustersKmeans__ - кластеры, образованные моделью Kmeans\n",
    "\n",
    "__clustersSpectral__ - кластеры, образованные моделью Spectral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735143a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfHabr1 = pd.read_csv('Report1.csv')\n",
    "mystem = Mystem() \n",
    "# добавление стопслов\n",
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "russian_stopwords.extend(['…', '«', '»', '...', 'быть', 'r', 'n', 'а', 'мы', 'с', 'для', 'ещё', 'его', 'также', 'к', 'тем', 'кто', 'чтобы', 'но', 'они', 'будут', 'так', 'где', 'один', 'он ', 'и', 'на', 'но', 'или', 'либо', 'это', 'мб', 'далее', 'дв', 'свой', 'ваш','всё', 'очень', 'её', 'ещё', 'вообще', 'наш', 'который'])\n",
    "def tokenize(text):\n",
    "    t = word_tokenize(text)\n",
    "    return [token for token in t if token not in russian_stopwords]\n",
    "\n",
    "\n",
    "dfHabr1['trigram'][i] = list(nltk.ngrams(dfHabr1['TextPostToken'][i], 3))\n",
    "freq_dist = nltk.FreqDist(dfHabr1['TextPostToken'][i])\n",
    "    top_words = [word for word, count in freq_dist.most_common(10)]\n",
    "    dfHabr1['keyword'][i] = ', '.join(top_words)\n",
    "    \n",
    "    \n",
    "def preprocess_text(data, stopwords=russian_stopwords):\n",
    "    text = re.sub('ё','е', data.lower())\n",
    "    text = text.strip()\n",
    "    text = [w for w in text.split() if w not in stopwords] \n",
    "    text = [w for w in text if len(w) >=3]\n",
    "    return ' '.join(text)\n",
    "\n",
    "def transform_data(data: pd.Series) -> list:\n",
    "    result = [preprocess_text(data=i) for i in data]\n",
    "    return result\n",
    "%%time\n",
    "dfHabr2 = transform_data(text)\n",
    "vectorizer = CountVectorizer(analyzer='word', stop_words=russian_stopwords, ngram_range=(1, 3), min_df=1)\n",
    "count_matrix = vectorizer.fit_transform(dfHabr2)\n",
    "agg = AgglomerativeClustering(n_clusters=11).fit(count_matrix.toarray())\n",
    "labelsAgglomerative = agg.labels_\n",
    "clusters1 = agg.labels_.tolist()\n",
    "cluster_counts = dfHabr1['clustersAgglomerative'].value_counts()\n",
    "plt.pie(cluster_counts.values, labels=cluster_counts.index, autopct='%1.1f%%')\n",
    "plt.show()\n",
    "a = (dfHabr1['clustersKmeans'] - dfHabr1['clustersKmeans'].mean()) / dfHabr1['clustersKmeans'].std()\n",
    "data_norm_kmeans = a.values.reshape(-1, 1)\n",
    "silhouette_avg = silhouette_score(data_norm_kmeans, km.labels_)\n",
    "print(\"Silhouette  score:\", silhouette_avg)\n",
    "# создание модели LDA\n",
    "lda_model = LatentDirichletAllocation(n_components=11, random_state=0)\n",
    "lda_model.fit(count_matrix)\n",
    "\n",
    "# вывод топ слов для каждой темы\n",
    "for i, topic in enumerate(lda_model.components_):\n",
    "    print(f\"Topic {i}: {', '.join([vectorizer.get_feature_names_out()[i] for i in topic.argsort()[:-11:-1]])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef5deef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создание матрицы документ-термин\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=russian_stopwords)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(dfHabr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48abd72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создание модели NMF\n",
    "nmf_model = NMF(n_components=11, random_state=0)\n",
    "nmf_model.fit(tfidf_matrix)\n",
    "\n",
    "# вывод топ слов для каждой темы\n",
    "for i, topic in enumerate(nmf_model.components_):\n",
    "    print(f\"Topic {i}: {', '.join([tfidf_vectorizer.get_feature_names_out()[i] for i in topic.argsort()[:-11:-1]])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3cca1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "# визуализация модели LDA\n",
    "panel = pyLDAvis.sklearn.prepare(lda_model, count_matrix, vectorizer, mds='tsne', sort_topics=False)\n",
    "panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac607ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = []\n",
    "\n",
    "for i, topic in enumerate(lda_model.components_):\n",
    "    top_words = [vectorizer.get_feature_names_out()[i] for i in topic.argsort()[:-11:-1]]\n",
    "    topic_string = f\"Topic {i}: {', '.join(top_words)}\"\n",
    "    topics.append(topic_string)\n",
    "dfCosinTest = pd.DataFrame({'texts': topics})\n",
    "for i in range(0, 11):\n",
    "    find_nearest_to = str(dfHabr1.loc[dfHabr1['clustersAgglomerative'] == i, 'keyword'])\n",
    "    # формирование весов tf-idf\n",
    "    tfidf = TfidfVectorizer()\n",
    "    mx_tf = tfidf.fit_transform(topics)\n",
    "    new_entry = tfidf.transform([find_nearest_to])\n",
    "    sdf = pd.DataFrame.sparse.from_spmatrix(mx_tf)\n",
    "    new_entry = tfidf.transform([find_nearest_to])\n",
    "    pd.DataFrame.sparse.from_spmatrix(new_entry)\n",
    "    cosine_similarities = cosine_similarity(new_entry, mx_tf).flatten()\n",
    "    dfCosinTest['cos_similarities'] = cosine_similarities\n",
    "    dfCosinTest = dfCosinTest.sort_values(by=['cos_similarities'], ascending=[0])\n",
    "    dfCosinTest = dfCosinTest.reset_index(drop=True)\n",
    "    dfj['texts'].append(dfCosinTest['texts'][0])\n",
    "    dfj['cos_similarities'].append(dfCosinTest['cos_similarities'][0])\n",
    "    dfj['cluster'].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07299fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='TitleCompany', kind='count', data=dfHabr1)\n",
    "sns.catplot(x='Reiting', kind='count', data=dfHabr1)\n",
    "sns.catplot(x='Categories', kind='count', data=dfHabr1)\n",
    "# анализ плотности распределения целевой переменной\n",
    "sns.kdeplot(dfHabr1['clustersAgglomerative'], shade=True)\n",
    "# визуализация зависимости кластеров от временных признаков\n",
    "plt.scatter(dfHabr1['TitleCompany'], dfHabr1['clustersAgglomerative'])\n",
    "plt.xlabel('Title')\n",
    "plt.ylabel('Cluster')\n",
    "plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a25fe73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
